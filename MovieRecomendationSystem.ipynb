{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "MovieRecomendationSystem.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAIGANESH02/Movie-Recommendation-System/blob/main/MovieRecomendationSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjotzBjsAQ3W"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57lNLCX8AQ3Y"
      },
      "source": [
        "# Here we are creating a spark context\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "# Loading the raw ratings data from 100k dataset into spark as a RDD\n",
        "small_ratings_file = r\"C:\\Users\\Vamsi Reddy\\SparkProj\\MoviLenseRecomend\\Datasets\\ml-latest-small\\ratings.csv\"\n",
        "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
        "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuQ7GNnwAQ3Z"
      },
      "source": [
        "# Now we can parse the raw ratings data into a new RDD. of the form (UserID, MovieID, Rating)\n",
        "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header).map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX0sF1ruAQ3Z",
        "outputId": "40fd39e3-f134-431a-b79e-a8781a00f52b"
      },
      "source": [
        "# Printing to verify \n",
        "small_ratings_data.take(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NXY5_ERAQ3a",
        "outputId": "8d992d5c-e1b9-4638-b5ae-64c9a252ad40"
      },
      "source": [
        "# Loading the raw movies.csv data from 100k dataset into spark as a RDD\n",
        "small_movies_file = r\"C:\\Users\\Vamsi Reddy\\SparkProj\\MoviLenseRecomend\\Datasets\\ml-latest-small\\movies.csv\"\n",
        "\n",
        "small_movies_raw_data = sc.textFile(small_movies_file)\n",
        "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
        "\n",
        "# Now we can parse the raw ratings data into a new RDD. of the form (MovieID, Title)\n",
        "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header).map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
        "\n",
        "# Printing to verify \n",
        "small_movies_data.take(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 'Toy Story (1995)'),\n",
              " ('2', 'Jumanji (1995)'),\n",
              " ('3', 'Grumpier Old Men (1995)')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwGfr2MwAQ3b"
      },
      "source": [
        "# We split ratings dataset into train, validation, and test datasets.\n",
        "# This is done because we use this to get the best ALS parameters \n",
        "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
        "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
        "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljBl6FJaAQ3b",
        "outputId": "72bd1930-7226-4fde-badb-5e82b8b12b30"
      },
      "source": [
        "# Using validation_rdd to know the best number of latent factors for the dataset we have\n",
        "from pyspark.mllib.recommendation import ALS\n",
        "import math\n",
        "\n",
        "seed = 5\n",
        "iterations = 10\n",
        "regularization_parameter = 0.1\n",
        "ranks = [4, 8, 12]\n",
        "errors = [0, 0, 0]\n",
        "err = 0\n",
        "tolerance = 0.02\n",
        "\n",
        "min_error = float('inf')\n",
        "best_rank = -1\n",
        "best_iteration = -1\n",
        "for rank in ranks:\n",
        "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
        "                      lambda_=regularization_parameter)\n",
        "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
        "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "    errors[err] = error\n",
        "    err += 1\n",
        "    print('For rank %s the RMSE is %s' % (rank, error))\n",
        "    if error < min_error:\n",
        "        min_error = error\n",
        "        best_rank = rank\n",
        "\n",
        "print('The best model was trained with rank %s' % best_rank)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For rank 4 the RMSE is 0.8973056100718643\n",
            "For rank 8 the RMSE is 0.9143149069672253\n",
            "For rank 12 the RMSE is 0.9141049207539428\n",
            "The best model was trained with rank 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP736yBAAQ3c",
        "outputId": "76247619-1ba2-42b7-c9b4-2c79a37f5154"
      },
      "source": [
        "# printing and verifying\n",
        "validation_for_predict_RDD.take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', '6'), ('1', '47')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBkZNJ0XAQ3c",
        "outputId": "aec07042-81cb-4b3c-9fcd-2afe9694e760"
      },
      "source": [
        "# printing and verifying \n",
        "predictions.take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((249, 69069), 3.3365203516084856), ((68, 69069), 3.1620382534666387)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1OcFoibAQ3c"
      },
      "source": [
        "# Load the complete dataset file\n",
        "complete_ratings_file = r\"C:\\Users\\Vamsi Reddy\\SparkProj\\MoviLenseRecomend\\Datasets\\ml-latest\\ratings.csv\"\n",
        "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
        "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6wuGBtGAQ3d",
        "outputId": "fa98ad4d-f422-41e9-e9a3-be88653bc634"
      },
      "source": [
        "# Parsing the data same way as 100k dataset\n",
        "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header).map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
        "print(\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 27753444 recommendations in the complete dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APzgHUeQAQ3d"
      },
      "source": [
        "# splitting the complete data using training and testing dataset and Building the ASL model using the \n",
        "# previously found hyperparameters\n",
        "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
        "\n",
        "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
        "                           iterations=iterations, lambda_=regularization_parameter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmtvlIAEAQ3e",
        "outputId": "5afb4a0e-f663-4200-8087-94528421ca9b"
      },
      "source": [
        "# Now we test on our testing set.\n",
        "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
        "\n",
        "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
        "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "print('For testing data the RMSE is %s' % (error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For testing data the RMSE is 0.8334782410156314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QulA8tOkAQ3e",
        "outputId": "c6b5f7ef-1830-4a5d-f3c4-bdc370bdb4e4"
      },
      "source": [
        "# load the movies complete file\n",
        "complete_movies_file = r\"C:\\Users\\Vamsi Reddy\\SparkProj\\MoviLenseRecomend\\Datasets\\ml-latest\\movies.csv\"\n",
        "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
        "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
        "\n",
        "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
        "\n",
        "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
        "    \n",
        "print(\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 58098 movies in the complete dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjQWZ1heAQ3f"
      },
      "source": [
        "# function to count the number of ratings per movie.\n",
        "def get_counts_and_averages(ID_and_ratings_tuple):\n",
        "    nratings = len(ID_and_ratings_tuple[1])\n",
        "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
        "\n",
        "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
        "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
        "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdE5yrbuAQ3f",
        "outputId": "72cc4ef9-45f0-405a-c5ab-b44fb8fe9127"
      },
      "source": [
        "# Adding new user ratings\n",
        "new_user_ID = 0\n",
        "\n",
        "# The format of each line is (userID, movieID, rating)\n",
        "new_user_ratings = [\n",
        "     (0,260,4), # Star Wars (1977)\n",
        "     (0,1,3), # Toy Story (1995)\n",
        "     (0,16,3), # Casino (1995)\n",
        "     (0,25,4), # Leaving Las Vegas (1995)\n",
        "     (0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
        "     (0,335,1), # Flintstones, The (1994)\n",
        "     (0,379,1), # Timecop (1994)\n",
        "     (0,296,3), # Pulp Fiction (1994)\n",
        "     (0,858,5) , # Godfather, The (1972)\n",
        "     (0,50,4) # Usual Suspects, The (1995)\n",
        "    ]\n",
        "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
        "print('New user ratings: %s' % new_user_ratings_RDD.take(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New user ratings: [(0, 260, 4), (0, 1, 3), (0, 16, 3), (0, 25, 4), (0, 32, 4), (0, 335, 1), (0, 379, 1), (0, 296, 3), (0, 858, 5), (0, 50, 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTewz_G6AQ3g"
      },
      "source": [
        "# Now we add them to the data we will use to train our recommender model\n",
        "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XIjdljoAQ3g",
        "outputId": "5f3b3f6e-eb2c-48f4-cb6c-95c43b3bfb36"
      },
      "source": [
        "# training the ALS model using all the parameters we selected before (when using the small dataset).\n",
        "from time import time\n",
        "\n",
        "t0 = time()\n",
        "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
        "                              iterations=iterations, lambda_=regularization_parameter)\n",
        "tt = time() - t0\n",
        "\n",
        "print(\"New model trained in %s seconds\" % round(tt,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New model trained in 169.906 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU9f5qhBAQ3g"
      },
      "source": [
        "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
        "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
        "\n",
        "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
        "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBZtqxiHAQ3g",
        "outputId": "1b251988-594f-4fcd-b9cd-2929166ca8e2"
      },
      "source": [
        "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
        "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
        "new_user_recommendations_rating_title_and_count_RDD = \\\n",
        "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
        "new_user_recommendations_rating_title_and_count_RDD.take(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(7020, ((3.0758903881085082, 'Proof (1991)'), 377)),\n",
              " (53352, ((2.11427667988852, 'Sheitan (2006)'), 59)),\n",
              " (162396, ((0.9736832918466494, 'Skiptrace (2016)'), 71))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaC73QT4AQ3h"
      },
      "source": [
        "# Transform to the form (Title, Rating, Ratings Count)\n",
        "new_user_recommendations_rating_title_and_count_RDD = \\\n",
        "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xop5NKTsAQ3h",
        "outputId": "758b2abb-7757-4dc6-c193-b1b567be837f"
      },
      "source": [
        "# filtering out movies with less than 25 ratings.\n",
        "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
        "\n",
        "# get the highest rated recommendations for the new user\n",
        "print ('TOP recommended movies (with more than 25 reviews):\\n%s' %\n",
        "        '\\n'.join(map(str, top_movies)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOP recommended movies (with more than 25 reviews):\n",
            "('Elway To Marino (2013)', 4.03702785250745, 25)\n",
            "('Rabbit of Seville (1950)', 4.002279522928873, 30)\n",
            "('\"Human Condition III', 3.99453726418848, 91)\n",
            "('Harakiri (Seppuku) (1962)', 3.9061620070327905, 679)\n",
            "('Wow! A Talking Fish! (1983)', 3.8586009958174685, 47)\n",
            "('\"Last Lions', 3.8585627928003063, 38)\n",
            "('Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)', 3.8577707893893347, 29484)\n",
            "('Rebels of the Neon God (Qing shao nian nuo zha) (1992)', 3.852821730679487, 28)\n",
            "(\"Jim Henson's The Storyteller (1989)\", 3.8492614693875, 36)\n",
            "('Cosmos', 3.8487806839748657, 157)\n",
            "('\"Great War', 3.845119718097372, 31)\n",
            "('\"Godfather', 3.840897941465556, 60904)\n",
            "('Crooks in Clover (a.k.a. Monsieur Gangster) (Les tontons flingueurs) (1963)', 3.8365516701854787, 52)\n",
            "('Death on the Staircase (Soupçons) (2004)', 3.828444877084493, 130)\n",
            "('Music for One Apartment and Six Drummers (2001)', 3.8275481951426045, 31)\n",
            "('\"Century of the Self', 3.826311342369383, 213)\n",
            "('Small Potatoes - Who Killed the USFL? (2009)', 3.8204550623839424, 26)\n",
            "('Dimensions of Dialogue (Moznosti dialogu) (1982)', 3.8185043636782297, 65)\n",
            "('Rabbit Fire (1951)', 3.8170494565645114, 46)\n",
            "('Ikiru (1952)', 3.809830295651391, 1551)\n",
            "('\"Ascent', 3.807571981945234, 63)\n",
            "('\"Third Man', 3.8038717130762123, 7980)\n",
            "('Paths of Glory (1957)', 3.802279723817186, 4508)\n",
            "('Seven Samurai (Shichinin no samurai) (1954)', 3.800167197408424, 14578)\n",
            "('All Watched Over by Machines of Loving Grace (2011)', 3.799707879885826, 157)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72W73XskAQ3h",
        "outputId": "415bf22a-b137-4107-a909-b1204b4646d6"
      },
      "source": [
        "# Trying to predict the rating for a specific movie\n",
        "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\n",
        "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
        "individual_movie_rating_RDD.take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Rating(user=0, product=116688, rating=0.8086061251091987)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AdcohhpAQ3i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}